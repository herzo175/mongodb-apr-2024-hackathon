{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aadf37b5-ee95-4313-b711-5ed91c7ddc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremy.herzog/.pyenv/versions/3.11.4/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer\n",
    "from PIL import Image\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "402a47bc-5030-47d5-8201-b02600e8c80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionEncoderDecoderModel(\n",
       "  (encoder): ViTModel(\n",
       "    (embeddings): ViTEmbeddings(\n",
       "      (patch_embeddings): ViTPatchEmbeddings(\n",
       "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): ViTEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (pooler): ViTPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (decoder): GPT2LMHeadModel(\n",
       "    (transformer): GPT2Model(\n",
       "      (wte): Embedding(50257, 768)\n",
       "      (wpe): Embedding(1024, 768)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (h): ModuleList(\n",
       "        (0-11): 12 x GPT2Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (crossattention): GPT2Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (q_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_cross_attn): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "feature_extractor = ViTImageProcessor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "509cfd0e-f428-438d-873a-796cf26e6905",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 16\n",
    "num_beams = 4\n",
    "gen_kwargs = {\"max_length\": max_length, \"num_beams\": num_beams}\n",
    "\n",
    "def predict_step(image_paths):\n",
    "  images = []\n",
    "  for image_path in image_paths:\n",
    "    i_image = Image.open(image_path)\n",
    "    if i_image.mode != \"RGB\":\n",
    "      i_image = i_image.convert(mode=\"RGB\")\n",
    "\n",
    "    images.append(i_image)\n",
    "\n",
    "  pixel_values = feature_extractor(images=images, return_tensors=\"pt\").pixel_values\n",
    "  pixel_values = pixel_values.to(device)\n",
    "\n",
    "  output_ids = model.generate(pixel_values, **gen_kwargs)\n",
    "\n",
    "  preds = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "  preds = [pred.strip() for pred in preds]\n",
    "  return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c43a024-e36d-411d-bbd3-5a3ba80edc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "You may ignore this warning if your `pad_token_id` (50256) is identical to the `bos_token_id` (50256), `eos_token_id` (50256), or the `sep_token_id` (None), and your input is not padded.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a man kicking a soccer ball on a field']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ['a man kicking a soccer ball on a field']\n",
    "predict_step(['football-match.jpeg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f914001-ba55-4118-85c0-0e629ecdb2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "# NOTE: must brew install ffmpeg as well\n",
    "import numpy as np\n",
    "\n",
    "width = 640\n",
    "height = 640\n",
    "\n",
    "def process_video(in_filename):\n",
    "    process = (\n",
    "    \tffmpeg.input(in_filename)\n",
    "    \t.output('frames/frame%d.png', vf=\"select=not(mod(n\\,15))\", vsync=\"vfr\")\n",
    "    \t.run_async(pipe_stdout=True)\n",
    "    )\n",
    "\n",
    "    process.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7af0e44-cf2d-4dea-a1bc-386c383ca597",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with Apple clang version 14.0.0 (clang-1400.0.29.202)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/6.1.1_7 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags= --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libopenvino --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "-vsync is deprecated. Use -fps_mode\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'm2-res_640p.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf59.27.100\n",
      "  Duration: 00:00:19.24, start: 0.000000, bitrate: 548 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 360x640 [SAR 1:1 DAR 9:16], 413 kb/s, 30 fps, 30 tbr, 15360 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : AVC Coding\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 127 kb/s (default)\n",
      "    Metadata:\n",
      "      handler_name    : SoundHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> png (native))\n",
      "Press [q] to stop, [?] for help\n",
      "[swscaler @ 0x120208000] [swscaler @ 0x1500d8000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x120208000] [swscaler @ 0x1500e8000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x120208000] [swscaler @ 0x1500f8000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x120208000] [swscaler @ 0x150108000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x120208000] [swscaler @ 0x150148000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x120208000] [swscaler @ 0x150158000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x120208000] [swscaler @ 0x150168000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x120208000] [swscaler @ 0x150178000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x120208000] [swscaler @ 0x150188000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x120208000] [swscaler @ 0x150198000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x120208000] [swscaler @ 0x1501a8000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x1501a8000] [swscaler @ 0x140820000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x1501a8000] [swscaler @ 0x140830000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x1501a8000] [swscaler @ 0x130450000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x1501a8000] [swscaler @ 0x130460000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x1501a8000] [swscaler @ 0x130470000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x1501a8000] [swscaler @ 0x130480000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x1501a8000] [swscaler @ 0x130490000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x1501a8000] [swscaler @ 0x1304a0000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x1501a8000] [swscaler @ 0x1304b0000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x1501a8000] [swscaler @ 0x1304c0000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x1501a8000] [swscaler @ 0x1304d0000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x140830000] [swscaler @ 0x110378000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x140830000] [swscaler @ 0x110388000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x140830000] [swscaler @ 0x110398000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x140830000] [swscaler @ 0x1103a8000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x140830000] [swscaler @ 0x1103b8000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x140830000] [swscaler @ 0x1103c8000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x140830000] [swscaler @ 0x1103d8000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x140830000] [swscaler @ 0x1103e8000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x140830000] [swscaler @ 0x1103f8000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x140830000] [swscaler @ 0x110408000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x140830000] [swscaler @ 0x110418000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x110418000] [swscaler @ 0x110378000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x110418000] [swscaler @ 0x110388000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x110418000] [swscaler @ 0x110398000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x110418000] [swscaler @ 0x1103a8000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x110418000] [swscaler @ 0x1103b8000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x110418000] [swscaler @ 0x1103c8000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x110418000] [swscaler @ 0x1103d8000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x110418000] [swscaler @ 0x1103e8000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x110418000] [swscaler @ 0x1103f8000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x110418000] [swscaler @ 0x110408000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x110418000] [swscaler @ 0x1381b0000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "Output #0, image2, to 'frames/frame%d.png':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf60.16.100\n",
      "  Stream #0:0(und): Video: png, rgb24(pc, gbr/bt709/bt709, progressive), 360x640 [SAR 1:1 DAR 9:16], q=2-31, 200 kb/s, 30 fps, 30 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "      encoder         : Lavc60.31.102 png\n",
      "[out#0/image2 @ 0x14d8047b0] video:7483kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
      "frame=   39 fps=0.0 q=-0.0 Lsize=N/A time=00:00:19.00 bitrate=N/A speed= 158x    \n"
     ]
    }
   ],
   "source": [
    "process_video('m2-res_640p.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9a0603-24aa-41f6-b2f3-208eb32809c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
